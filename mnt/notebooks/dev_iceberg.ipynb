{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f85802c-aa1d-4fb5-8dd6-a76abf9cd43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/12 00:43:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28013613-12e5-44a4-8ef1-45fe35f2e93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Listar tabelas\n",
    "spark.sql(\"SHOW TABLES IN nessie\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b51fa4-c879-48c7-b80a-9aa2bb48fdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE NAMESPACE IF NOT EXISTS nessie.bronze\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"CREATE NAMESPACE IF NOT EXISTS nessie.silver\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"CREATE NAMESPACE IF NOT EXISTS nessie.gold\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70292e68-8516-4d70-81ac-b527d86a8b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bronze Tables\n",
    "\n",
    "spark.sql(open(\"settings/create_bronze_vocation.sql\").read())\n",
    "spark.sql(open(\"settings/create_bronze_extra.sql\").read())\n",
    "spark.sql(open(\"settings/create_bronze_skills.sql\").read())\n",
    "\n",
    "# Silver Tables\n",
    "spark.sql(open(\"settings/create_silver_vocation.sql\").read())\n",
    "spark.sql(open(\"settings/create_silver_extra.sql\").read())\n",
    "spark.sql(open(\"settings/create_silver_skills.sql\").read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "178179e7-eeb2-4bc2-959b-e62621e17a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   bronze|    extra|      false|\n",
      "|   bronze|   skills|      false|\n",
      "|   bronze| vocation|      false|\n",
      "|   silver|    extra|      false|\n",
      "|   silver|   skills|      false|\n",
      "|   silver| vocation|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Listar tabelas\n",
    "spark.sql(\"SHOW TABLES IN nessie\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41fbbc3-71a5-43cc-a348-10c82b6650c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1df3973-1264-466a-8817-dafbfb2b4506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/20 22:58:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff234485-c654-4659-b131-31db923952f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS nessie.bronze.extra\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS nessie.silver.extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e8e704-94b8-451c-a3f6-241dd5c082e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   bronze|   skills|      false|\n",
      "|   bronze| vocation|      false|\n",
      "|   silver|   skills|      false|\n",
      "|   silver| vocation|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bf0691-3c33-499e-b484-e3bbd6dae7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13614f7f-2325-4083-9702-23687a3611cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "26/01/20 22:59:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "26/01/20 22:59:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "26/01/20 22:59:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "26/01/20 23:00:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "26/01/20 23:00:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\" CREATE OR REPLACE TABLE nessie.gold.vocation_rank_global\n",
    "USING iceberg\n",
    "AS\n",
    "SELECT\n",
    "      ROW_NUMBER() OVER (ORDER BY level DESC) AS rank\n",
    "    , name\n",
    "    , world\n",
    "    , vocation\n",
    "    , level\n",
    "    , experience\n",
    "    , world_type\n",
    "    , current_timestamp() AS updated_at\n",
    "FROM nessie.silver.vocation\n",
    "WHERE is_current = true;\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bb7adb-6ffb-4828-b895-d4746c7acab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|vocation_rank_global|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911f620d-fbdc-43c2-b60a-89d377d35a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+\n",
      "|rank|             name|   world|       vocation|level|  experience|  world_type|          updated_at|\n",
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+\n",
      "|   1|        Dejairzin|  inabra|    elder druid| 2997|447914003765|    Open PvP|2026-01-20 22:59:...|\n",
      "|   2|           Bobeek|    bona|    elder druid| 2958|430572283021|Optional PvP|2026-01-20 22:59:...|\n",
      "|   3|           Goraca|    bona|master sorcerer| 2955|429183508697|Optional PvP|2026-01-20 22:59:...|\n",
      "|   4|          Veyllor|gentebra|  royal paladin| 2909|409683078307|Optional PvP|2026-01-20 22:59:...|\n",
      "|   5|   Warlord Teuzin| belobra|master sorcerer| 2877|396292619074|Optional PvP|2026-01-20 22:59:...|\n",
      "|   6|            Vepeh| celebra|  royal paladin| 2861|389654187727|Optional PvP|2026-01-20 22:59:...|\n",
      "|   7|       Mago Morto| celebra|master sorcerer| 2798|364591370274|Optional PvP|2026-01-20 22:59:...|\n",
      "|   8|        Kommander| celebra|  royal paladin| 2792|361974233480|Optional PvP|2026-01-20 22:59:...|\n",
      "|   9|   Warlord Leonny| belobra|  royal paladin| 2784|358952215806|Optional PvP|2026-01-20 22:59:...|\n",
      "|  10|         Ke vinho|gentebra|    elder druid| 2784|358904530744|Optional PvP|2026-01-20 22:59:...|\n",
      "|  11|    Warlord Bread| belobra|    elder druid| 2782|358463654877|Optional PvP|2026-01-20 22:59:...|\n",
      "|  12|           Baaeck|gentebra|master sorcerer| 2716|333392277789|Optional PvP|2026-01-20 22:59:...|\n",
      "|  13|            Galll|gentebra|   elite knight| 2709|330657551203|Optional PvP|2026-01-20 22:59:...|\n",
      "|  14|   Izzy The Beast| celebra|    elder druid| 2678|319387724396|Optional PvP|2026-01-20 22:59:...|\n",
      "|  15|           Szimix| celesta|    elder druid| 2629|302193405655|Optional PvP|2026-01-20 22:59:...|\n",
      "|  16|             Teus|descubra|master sorcerer| 2621|299594910860|Optional PvP|2026-01-20 22:59:...|\n",
      "|  17|         Ferangel|    bona|  royal paladin| 2583|286876273076|Optional PvP|2026-01-20 22:59:...|\n",
      "|  18|   Khaos Poderoso|  unebra|master sorcerer| 2582|286391478123|    Open PvP|2026-01-20 22:59:...|\n",
      "|  19|Marcao Implacavel| kalibra|    elder druid| 2567|281445783524|Optional PvP|2026-01-20 22:59:...|\n",
      "|  20|       Elder Reno| celesta|    elder druid| 2527|268353964612|Optional PvP|2026-01-20 22:59:...|\n",
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" SELECT * FROM nessie.gold.vocation_rank_global \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1822721f-75e2-42dd-a491-e4a7cf15a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2babc50-2617-4d28-b409-71bb466766c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/26 18:19:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cc27cc-90b9-48ef-8c2f-77a8a63f78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|experience_rank_g...|      false|\n",
      "|     gold|  skills_rank_global|      false|\n",
      "|     gold|vocation_rank_global|      false|\n",
      "|     gold|       world_summary|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1774571-b80e-41f3-8255-0b152cfbd8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    }
   ],
   "source": [
    "tables_gold = [\n",
    "    \"nessie.gold.experience_rank_global\",\n",
    "    \"nessie.gold.skills_rank_global\",\n",
    "    \"nessie.gold.vocation_rank_global\",\n",
    "    \"nessie.gold.world_summary\"\n",
    "]\n",
    "\n",
    "for table in tables_gold:\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04083450-cdfa-49c9-afaa-cb657ada6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   bronze|   skills|      false|\n",
      "|   bronze| vocation|      false|\n",
      "|   silver|   skills|      false|\n",
      "|   silver| vocation|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04b9eb0-d34c-4bb4-821e-b7f1f3870593",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe69899-b56a-47c7-a1be-c1def3d92017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|experience_rank_g...|      false|\n",
      "|     gold|  skills_rank_global|      false|\n",
      "|     gold|       world_summary|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d512bfa-93b0-4e5d-89f5-d556e3386a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3db209-be30-419f-bfd8-a22dd7ec71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e369ab39-8f41-4da2-950d-835a88cfa1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 9.6 MB/s eta 0:00:01    |████████████████████████▎       | 9.4 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[K     |████████████████████████████████| 348 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.20.3; python_version < \"3.10\"\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 7.8 MB/s eta 0:00:01    |█████████████▌                  | 7.3 MB 9.1 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 tzdata-2025.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2774b-c982-495d-8e96-882fb5306c1f",
   "metadata": {},
   "source": [
    "# EXPORTANDO AS TABELAS PARA CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c37456b9-3e51-4aa6-9c2e-02740ab837b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/26 19:28:45 WARN S3FileIO: Unclosed S3FileIO instance created by:\n",
      "\torg.apache.iceberg.aws.s3.S3FileIO.initialize(S3FileIO.java:359)\n",
      "\torg.apache.iceberg.CatalogUtil.loadFileIO(CatalogUtil.java:351)\n",
      "\torg.apache.iceberg.nessie.NessieCatalog.initialize(NessieCatalog.java:132)\n",
      "\torg.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:256)\n",
      "\torg.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:310)\n",
      "\torg.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:154)\n",
      "\torg.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:753)\n",
      "\torg.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n",
      "\torg.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:54)\n",
      "\tscala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n",
      "\torg.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:54)\n",
      "\torg.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)\n",
      "\torg.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)\n",
      "\torg.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\n",
      "\torg.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)\n",
      "\torg.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)\n",
      "\torg.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.ShowTables.mapChildren(v2Commands.scala:879)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)\n",
      "\torg.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)\n",
      "\torg.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tscala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tscala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tscala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tscala.collection.immutable.List.foreach(List.scala:431)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)\n",
      "\torg.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\torg.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\torg.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\torg.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\torg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\torg.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\torg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\torg.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\torg.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\torg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\torg.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\torg.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tjava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tjava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tjava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tjava.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tpy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tpy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tpy4j.Gateway.invoke(Gateway.java:282)\n",
      "\tpy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tpy4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tpy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tpy4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tjava.base/java.lang.Thread.run(Unknown Source)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# BRONZE\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.bronze.vocation\n",
    "    \"\"\").toPandas()).to_csv(\"bronze_vocation.csv\")\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.bronze.skills\n",
    "    \"\"\").toPandas()).to_csv(\"bronze_skills.csv\")\n",
    "\n",
    "# SILVER\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.silver.skills\n",
    "    \"\"\").toPandas()).to_csv(\"silver_skills.csv\")\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.silver.vocation\n",
    "    \"\"\").toPandas()).to_csv(\"silver_vocation.csv\")\n",
    "\n",
    "# GOLD\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.gold.skills_rank_global\n",
    "    \"\"\").toPandas()).to_csv(\"gold_skills_rank_global.csv\")\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.gold.experience_rank_global\n",
    "    \"\"\").toPandas()).to_csv(\"gold_experience_rank_global.csv\")\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.gold.world_summary\n",
    "    \"\"\").toPandas()).to_csv(\"gold_world_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77ddcc9c-036f-44c5-aa29-df77a9d1503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feafacbd-20a1-4eef-b806-96f5629e7555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/04 00:20:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|experience_progre...|      false|\n",
      "|     gold|experience_rank_g...|      false|\n",
      "|     gold|  skills_progression|      false|\n",
      "|     gold|  skills_rank_global|      false|\n",
      "|     gold|       world_summary|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a889c6e0-6aa9-4d98-a542-f793e42d2a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "ALTER TABLE nessie.gold.experience_rank_global\n",
    "ADD COLUMN snapshot_date DATE;\n",
    " \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863698ad-de0d-4e59-b8ba-3e4e583848e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "UPDATE nessie.gold.experience_rank_global\n",
    "SET snapshot_date = DATE(updated_at)\n",
    "WHERE snapshot_date IS NULL;\n",
    " \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6ec4dd-9893-4ef0-b931-3124f1126480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|snapshot_date|count(1)|\n",
      "+-------------+--------+\n",
      "|   2026-02-03|   27991|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" -- Quantos snapshots existem\n",
    "SELECT snapshot_date, COUNT(*)\n",
    "FROM nessie.gold.experience_rank_global\n",
    "GROUP BY snapshot_date\n",
    "ORDER BY snapshot_date;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594277ad-7e1e-4296-b028-526cdb6b083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+-------------+\n",
      "|rank|             name|   world|       vocation|level|  experience|  world_type|          updated_at|snapshot_date|\n",
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+-------------+\n",
      "|   1|        Dejairzin|  inabra|    elder druid| 3008|453035989553|    Open PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|   2|           Bobeek|    bona|    elder druid| 2968|435074785284|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|   3|           Goraca|    bona|master sorcerer| 2965|433618397604|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|   4|          Veyllor|gentebra|  royal paladin| 2918|413378870792|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|   5|     Warlord Teus| belobra|master sorcerer| 2883|398878597327|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|   6|   Warlord Teuzin| belobra|master sorcerer| 2877|396292619074|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|   7|            Vepeh| celebra|  royal paladin| 2871|393818868975|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|   8|       Mago Morto| celebra|master sorcerer| 2808|368466610221|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|   9|        Kommander| celebra|  royal paladin| 2803|366427594287|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  10|         Ke vinho|gentebra|    elder druid| 2797|363962068762|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  11|    Warlord Bread| belobra|    elder druid| 2795|363321864583|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  12|   Warlord Leonny| belobra|  royal paladin| 2795|363282847354|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  13|           Baaeck|gentebra|master sorcerer| 2727|337300869319|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  14|            Galll|gentebra|   elite knight| 2720|334951053838|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  15|   Izzy The Beast| celebra|    elder druid| 2690|323929172376|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  16|           Szimix| celesta|    elder druid| 2640|306232885584|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  17|             Teus|descubra|master sorcerer| 2638|305339702325|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  18|   Khaos Poderoso|  unebra|master sorcerer| 2594|290425112564|    Open PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  19|         Ferangel|    bona|  royal paladin| 2594|290305815379|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "|  20|Tejow Corporation| ustebra|   elite knight| 2589|288637670556|Optional PvP|2026-02-03 03:32:...|   2026-02-03|\n",
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM nessie.gold.experience_rank_global\n",
    "WHERE snapshot_date = DATE '2026-02-03'\n",
    "ORDER BY rank;\n",
    " \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4eddb4a-3b15-4137-8c87-e37be194664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/05 21:13:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|experience_progre...|      false|\n",
      "|     gold|experience_rank_g...|      false|\n",
      "|     gold|  skills_progression|      false|\n",
      "|     gold|  skills_rank_global|      false|\n",
      "|     gold|       world_summary|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"gold\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40671082-8b00-44f3-8f15-6b8efcb9c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "AWS_ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "S3_ENDPOINT = os.getenv(\"S3_ENDPOINT\")\n",
    "NESSIE_URI = os.getenv(\"NESSIE_URI\")\n",
    "\n",
    "\n",
    "def create_spark_session(appname: str):\n",
    "\n",
    "    master = \"spark://spark-master:7077\"\n",
    "\n",
    "    conf = (\n",
    "        pyspark.SparkConf()\n",
    "        .setAppName(appname)\n",
    "        .set(\"spark.master\", master)\n",
    "\n",
    "        # ============================================================\n",
    "        # EXTENSÕES ICEBERG\n",
    "        # ============================================================\n",
    "        .set(\n",
    "            \"spark.sql.extensions\",\n",
    "            \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\"\n",
    "        )\n",
    "\n",
    "        # ============================================================\n",
    "        # PERFORMANCE BÁSICA\n",
    "        # ============================================================\n",
    "        .set(\"spark.executor.instances\", \"1\")\n",
    "        .set(\"spark.executor.cores\", \"1\")\n",
    "        .set(\"spark.executor.memory\", \"2g\")\n",
    "        .set(\"spark.executor.memoryOverhead\", \"512m\")\n",
    "        .set(\"spark.driver.memory\", \"2g\")\n",
    "\n",
    "        .set(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "        .set(\"spark.default.parallelism\", \"8\")\n",
    "\n",
    "        # ============================================================\n",
    "        # CATÁLOGO NESSIE\n",
    "        # ============================================================\n",
    "        .set(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "        .set(\"spark.sql.catalog.nessie.type\", \"nessie\")\n",
    "        .set(\"spark.sql.catalog.nessie.uri\", NESSIE_URI)\n",
    "        .set(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "        .set(\"spark.sql.catalog.nessie.authentication.type\", \"NONE\")\n",
    "        .set(\"spark.sql.catalog.nessie.cache-enabled\", \"false\")\n",
    "        .set(\"spark.sql.catalog.nessie.warehouse\", \"s3a://lakehouse/\")\n",
    "        .set(\"spark.sql.catalog.nessie.client-api-version\", \"2\")\n",
    "\n",
    "        # ============================================================\n",
    "        # S3A -> MINIO\n",
    "        # ============================================================\n",
    "        .set(\"spark.hadoop.fs.defaultFS\", \"s3a://lakehouse\")\n",
    "        .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "        .set(\"spark.hadoop.fs.s3a.endpoint\", S3_ENDPOINT)\n",
    "        .set(\"spark.hadoop.fs.s3a.access.key\", AWS_ACCESS_KEY)\n",
    "        .set(\"spark.hadoop.fs.s3a.secret.key\", AWS_SECRET_KEY)\n",
    "        .set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "        .set(\n",
    "            \"spark.hadoop.fs.s3a.aws.credentials.provider\",\n",
    "            \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\"\n",
    "        )\n",
    "\n",
    "        # ============================================================\n",
    "        # ICEBERG WRITE SETTINGS\n",
    "        # ============================================================\n",
    "        .set(\"spark.sql.iceberg.write.distribution-mode\", \"none\")\n",
    "        .set(\"spark.sql.iceberg.write.fanout.enabled\", \"false\")\n",
    "    )\n",
    "\n",
    "    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "    return spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d7e26b-f3a2-4d06-96b0-41f26588c7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|experience_progre...|      false|\n",
      "|     gold|  skills_progression|      false|\n",
      "|     gold|  skills_rank_global|      false|\n",
      "|     gold|       world_summary|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session(\"gold\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8a00070-4bf7-42c8-8975-ebf682cc0dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP TABLE nessie.gold.experience_rank_global;\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b81dcafb-2318-42ef-8ace-131c74a868fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|experience_progre...|      false|\n",
      "|     gold|experience_rank_g...|      false|\n",
      "|     gold|  skills_progression|      false|\n",
      "|     gold|  skills_rank_global|      false|\n",
      "|     gold|       world_summary|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1df3b05-7ee6-4008-9b3b-95278ed59fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE IF NOT EXISTS nessie.gold.experience_rank_global (\n",
    "    rank INT,\n",
    "    name STRING,\n",
    "    world STRING,\n",
    "    vocation STRING,\n",
    "    level INT,\n",
    "    experience BIGINT,\n",
    "    world_type STRING,\n",
    "    updated_at TIMESTAMP,\n",
    "    snapshot_date DATE\n",
    ")\n",
    "USING iceberg; \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53762769-9911-433f-8ee9-615b177641f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.jobs.utils.gold import Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72553026-9ed0-4694-b9d1-de58088f0425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 21:21:18,047 - INFO - Atualizando ranking global de experiencia.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = Gold(spark)\n",
    "gold.experience_rank_atualizado()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa2635c6-8009-4ffd-b726-39cbeb2ea95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|snapshot_date|count(1)|\n",
      "+-------------+--------+\n",
      "|   2026-02-05|   27991|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" SELECT snapshot_date, count(*) FROM nessie.gold.experience_rank_global GROUP BY snapshot_date\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "211aa69b-3d9f-46d9-8ac7-181b8f985f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+-------------+\n",
      "|rank|             name|   world|       vocation|level|  experience|  world_type|          updated_at|snapshot_date|\n",
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+-------------+\n",
      "|   1|        Dejairzin|  inabra|    elder druid| 3008|453035989553|    Open PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|   2|           Bobeek|    bona|    elder druid| 2968|435074785284|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|   3|           Goraca|    bona|master sorcerer| 2965|433618397604|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|   4|          Veyllor|gentebra|  royal paladin| 2918|413378870792|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|   5|     Warlord Teus| belobra|master sorcerer| 2883|398878597327|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|   6|   Warlord Teuzin| belobra|master sorcerer| 2877|396292619074|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|   7|            Vepeh| celebra|  royal paladin| 2871|393818868975|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|   8|       Mago Morto| celebra|master sorcerer| 2808|368466610221|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|   9|        Kommander| celebra|  royal paladin| 2803|366427594287|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  10|         Ke vinho|gentebra|    elder druid| 2797|363962068762|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  11|    Warlord Bread| belobra|    elder druid| 2795|363321864583|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  12|   Warlord Leonny| belobra|  royal paladin| 2795|363282847354|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  13|           Baaeck|gentebra|master sorcerer| 2727|337300869319|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  14|            Galll|gentebra|   elite knight| 2720|334951053838|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  15|   Izzy The Beast| celebra|    elder druid| 2690|323929172376|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  16|           Szimix| celesta|    elder druid| 2640|306232885584|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  17|             Teus|descubra|master sorcerer| 2638|305339702325|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  18|   Khaos Poderoso|  unebra|master sorcerer| 2594|290425112564|    Open PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  19|         Ferangel|    bona|  royal paladin| 2594|290305815379|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "|  20|Tejow Corporation| ustebra|   elite knight| 2589|288637670556|Optional PvP|2026-02-05 21:21:...|   2026-02-05|\n",
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" SELECT * FROM nessie.gold.experience_rank_global\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86417104-e049-4c18-b843-12b34207420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------+\n",
      "|col_name     |data_type|comment|\n",
      "+-------------+---------+-------+\n",
      "|rank         |int      |NULL   |\n",
      "|name         |string   |NULL   |\n",
      "|world        |string   |NULL   |\n",
      "|vocation     |string   |NULL   |\n",
      "|level        |int      |NULL   |\n",
      "|experience   |bigint   |NULL   |\n",
      "|world_type   |string   |NULL   |\n",
      "|updated_at   |timestamp|NULL   |\n",
      "|snapshot_date|date     |NULL   |\n",
      "+-------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE TABLE nessie.gold.experience_rank_global\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dcc32ce-0318-40e7-871c-c9e08d644055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+----------------------------------------------------------------+\n",
      "|key                                       |value                                                           |\n",
      "+------------------------------------------+----------------------------------------------------------------+\n",
      "|current-snapshot-id                       |3304075381269194630                                             |\n",
      "|format                                    |iceberg/parquet                                                 |\n",
      "|format-version                            |2                                                               |\n",
      "|gc.enabled                                |false                                                           |\n",
      "|nessie.commit.id                          |327a67368cf41f1474598b128843ecebef52d1617b919e8c3ffab1938c574fee|\n",
      "|write.metadata.delete-after-commit.enabled|false                                                           |\n",
      "|write.parquet.compression-codec           |zstd                                                            |\n",
      "+------------------------------------------+----------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TBLPROPERTIES nessie.gold.experience_rank_global\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7669f3d9-f9c6-4edb-afa8-7574136755bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+---------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id|operation|manifest_list                                                                                                                                                 |summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "+-----------------------+-------------------+---------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2026-02-05 21:21:27.757|3304075381269194630|NULL     |append   |s3a://lakehouse/gold/experience_rank_global_4f933950-00fd-4f86-b07c-2d14054db475/metadata/snap-3304075381269194630-1-38de4bbc-7e84-4a0c-ab3e-214da67f4add.avro|{spark.app.id -> app-20260205211927-0007, added-data-files -> 1, added-records -> 27991, added-files-size -> 461713, changed-partition-count -> 1, total-records -> 27991, total-files-size -> 461713, total-data-files -> 1, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.3, app-id -> app-20260205211927-0007, engine-name -> spark, iceberg-version -> Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}|\n",
      "+-----------------------+-------------------+---------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nessie.gold.experience_rank_global.snapshots\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6902b01-bb99-4176-bfa2-2e26a9a282ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id          |operation|manifest_list                                                                                                                                     |summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "+-----------------------+-------------------+-------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2026-01-12 23:59:04.426|7700552417730382809|NULL               |overwrite|s3a://lakehouse/silver/vocation_a5a6c13a-aff7-435e-93d0-c3f77d5ba467/metadata/snap-7700552417730382809-1-fd659ffd-6ed2-4863-b299-155512d1bc72.avro|{spark.app.id -> app-20260112234851-0005, changed-partition-count -> 0, total-records -> 0, total-files-size -> 0, total-data-files -> 0, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.3, app-id -> app-20260112234851-0005, engine-name -> spark, iceberg-version -> Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}                                                                                                                                                                             |\n",
      "|2026-01-12 23:59:19.737|5278967734512158874|7700552417730382809|append   |s3a://lakehouse/silver/vocation_a5a6c13a-aff7-435e-93d0-c3f77d5ba467/metadata/snap-5278967734512158874-1-ebfc4f41-4f67-4a89-8ab3-6ebac38bba5a.avro|{spark.app.id -> app-20260112234851-0005, added-data-files -> 87, added-records -> 26832, added-files-size -> 1673867, changed-partition-count -> 87, total-records -> 26832, total-files-size -> 1673867, total-data-files -> 87, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.3, app-id -> app-20260112234851-0005, engine-name -> spark, iceberg-version -> Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}                                                                                    |\n",
      "|2026-01-18 13:29:03.301|5071031462327188515|5278967734512158874|overwrite|s3a://lakehouse/silver/vocation_a5a6c13a-aff7-435e-93d0-c3f77d5ba467/metadata/snap-5071031462327188515-1-f8abf5f9-c378-49f1-9bcb-50e4fad43c31.avro|{spark.app.id -> app-20260118125720-0005, added-data-files -> 87, deleted-data-files -> 87, added-records -> 26832, deleted-records -> 26832, added-files-size -> 1690362, removed-files-size -> 1673867, changed-partition-count -> 87, total-records -> 26832, total-files-size -> 1690362, total-data-files -> 87, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.3, app-id -> app-20260118125720-0005, engine-name -> spark, iceberg-version -> Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)} |\n",
      "|2026-01-18 13:29:23.637|2088889354817533786|5071031462327188515|append   |s3a://lakehouse/silver/vocation_a5a6c13a-aff7-435e-93d0-c3f77d5ba467/metadata/snap-2088889354817533786-1-f7592d10-25ae-4a22-9b9c-dec8c82255fb.avro|{spark.app.id -> app-20260118125720-0005, added-data-files -> 87, added-records -> 12055, added-files-size -> 937873, changed-partition-count -> 87, total-records -> 38887, total-files-size -> 2628235, total-data-files -> 174, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.3, app-id -> app-20260118125720-0005, engine-name -> spark, iceberg-version -> Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}                                                                                    |\n",
      "|2026-01-26 18:58:08.539|2712272077525394689|2088889354817533786|overwrite|s3a://lakehouse/silver/vocation_a5a6c13a-aff7-435e-93d0-c3f77d5ba467/metadata/snap-2712272077525394689-1-8b7b399e-230e-4cd5-8321-190dbeb1372d.avro|{spark.app.id -> app-20260126185532-0004, added-data-files -> 87, deleted-data-files -> 171, added-records -> 38871, deleted-records -> 38871, added-files-size -> 2256764, removed-files-size -> 2616364, changed-partition-count -> 87, total-records -> 38887, total-files-size -> 2268635, total-data-files -> 90, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.3, app-id -> app-20260126185532-0004, engine-name -> spark, iceberg-version -> Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}|\n",
      "|2026-01-26 18:58:38.421|6790915944452541072|2712272077525394689|append   |s3a://lakehouse/silver/vocation_a5a6c13a-aff7-435e-93d0-c3f77d5ba467/metadata/snap-6790915944452541072-1-8f7405d8-c21c-4a1e-a4b6-b03c2fde833f.avro|{spark.app.id -> app-20260126185532-0004, added-data-files -> 87, added-records -> 12575, added-files-size -> 964287, changed-partition-count -> 87, total-records -> 51462, total-files-size -> 3232922, total-data-files -> 177, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.3, app-id -> app-20260126185532-0004, engine-name -> spark, iceberg-version -> Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}                                                                                    |\n",
      "|2026-02-03 03:31:21.974|3278541500086469647|6790915944452541072|overwrite|s3a://lakehouse/silver/vocation_a5a6c13a-aff7-435e-93d0-c3f77d5ba467/metadata/snap-3278541500086469647-1-6b305e13-830d-48c9-b71f-e2fe7929195d.avro|{spark.app.id -> app-20260203032928-0003, added-data-files -> 87, deleted-data-files -> 169, added-records -> 51413, deleted-records -> 51413, added-files-size -> 2815271, removed-files-size -> 3200870, changed-partition-count -> 87, total-records -> 51462, total-files-size -> 2847323, total-data-files -> 95, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.3, app-id -> app-20260203032928-0003, engine-name -> spark, iceberg-version -> Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}|\n",
      "|2026-02-03 03:31:38.182|187591752785684054 |3278541500086469647|append   |s3a://lakehouse/silver/vocation_a5a6c13a-aff7-435e-93d0-c3f77d5ba467/metadata/snap-187591752785684054-1-7aaf9040-3a0e-46de-a977-1c65c49fe694.avro |{spark.app.id -> app-20260203032928-0003, added-data-files -> 87, added-records -> 12432, added-files-size -> 957093, changed-partition-count -> 87, total-records -> 63894, total-files-size -> 3804416, total-data-files -> 182, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0, engine-version -> 3.5.3, app-id -> app-20260203032928-0003, engine-name -> spark, iceberg-version -> Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)}                                                                                    |\n",
      "+-----------------------+-------------------+-------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/05 22:11:08 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-0e5ce6e2-a20f-4e40-84f0-1c0a35a4e94b. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-0e5ce6e2-a20f-4e40-84f0-1c0a35a4e94b\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:174)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:109)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:364)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:364)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:359)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2120)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:95)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2305)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2305)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2211)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:681)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n",
      "\tat java.base/java.lang.Thread.run(Unknown Source)\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nessie.silver.vocation.snapshots\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3f697-3425-4c4f-82aa-5939f1bb2944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
