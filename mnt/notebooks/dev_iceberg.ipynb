{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f85802c-aa1d-4fb5-8dd6-a76abf9cd43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/12 00:43:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28013613-12e5-44a4-8ef1-45fe35f2e93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Listar tabelas\n",
    "spark.sql(\"SHOW TABLES IN nessie\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b51fa4-c879-48c7-b80a-9aa2bb48fdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE NAMESPACE IF NOT EXISTS nessie.bronze\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"CREATE NAMESPACE IF NOT EXISTS nessie.silver\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"CREATE NAMESPACE IF NOT EXISTS nessie.gold\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70292e68-8516-4d70-81ac-b527d86a8b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bronze Tables\n",
    "\n",
    "spark.sql(open(\"settings/create_bronze_vocation.sql\").read())\n",
    "spark.sql(open(\"settings/create_bronze_extra.sql\").read())\n",
    "spark.sql(open(\"settings/create_bronze_skills.sql\").read())\n",
    "\n",
    "# Silver Tables\n",
    "spark.sql(open(\"settings/create_silver_vocation.sql\").read())\n",
    "spark.sql(open(\"settings/create_silver_extra.sql\").read())\n",
    "spark.sql(open(\"settings/create_silver_skills.sql\").read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "178179e7-eeb2-4bc2-959b-e62621e17a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   bronze|    extra|      false|\n",
      "|   bronze|   skills|      false|\n",
      "|   bronze| vocation|      false|\n",
      "|   silver|    extra|      false|\n",
      "|   silver|   skills|      false|\n",
      "|   silver| vocation|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Listar tabelas\n",
    "spark.sql(\"SHOW TABLES IN nessie\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41fbbc3-71a5-43cc-a348-10c82b6650c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1df3973-1264-466a-8817-dafbfb2b4506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/20 22:58:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff234485-c654-4659-b131-31db923952f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS nessie.bronze.extra\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS nessie.silver.extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e8e704-94b8-451c-a3f6-241dd5c082e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   bronze|   skills|      false|\n",
      "|   bronze| vocation|      false|\n",
      "|   silver|   skills|      false|\n",
      "|   silver| vocation|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bf0691-3c33-499e-b484-e3bbd6dae7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13614f7f-2325-4083-9702-23687a3611cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "26/01/20 22:59:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "26/01/20 22:59:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "26/01/20 22:59:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "26/01/20 23:00:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "26/01/20 23:00:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\" CREATE OR REPLACE TABLE nessie.gold.vocation_rank_global\n",
    "USING iceberg\n",
    "AS\n",
    "SELECT\n",
    "      ROW_NUMBER() OVER (ORDER BY level DESC) AS rank\n",
    "    , name\n",
    "    , world\n",
    "    , vocation\n",
    "    , level\n",
    "    , experience\n",
    "    , world_type\n",
    "    , current_timestamp() AS updated_at\n",
    "FROM nessie.silver.vocation\n",
    "WHERE is_current = true;\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bb7adb-6ffb-4828-b895-d4746c7acab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|vocation_rank_global|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911f620d-fbdc-43c2-b60a-89d377d35a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+\n",
      "|rank|             name|   world|       vocation|level|  experience|  world_type|          updated_at|\n",
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+\n",
      "|   1|        Dejairzin|  inabra|    elder druid| 2997|447914003765|    Open PvP|2026-01-20 22:59:...|\n",
      "|   2|           Bobeek|    bona|    elder druid| 2958|430572283021|Optional PvP|2026-01-20 22:59:...|\n",
      "|   3|           Goraca|    bona|master sorcerer| 2955|429183508697|Optional PvP|2026-01-20 22:59:...|\n",
      "|   4|          Veyllor|gentebra|  royal paladin| 2909|409683078307|Optional PvP|2026-01-20 22:59:...|\n",
      "|   5|   Warlord Teuzin| belobra|master sorcerer| 2877|396292619074|Optional PvP|2026-01-20 22:59:...|\n",
      "|   6|            Vepeh| celebra|  royal paladin| 2861|389654187727|Optional PvP|2026-01-20 22:59:...|\n",
      "|   7|       Mago Morto| celebra|master sorcerer| 2798|364591370274|Optional PvP|2026-01-20 22:59:...|\n",
      "|   8|        Kommander| celebra|  royal paladin| 2792|361974233480|Optional PvP|2026-01-20 22:59:...|\n",
      "|   9|   Warlord Leonny| belobra|  royal paladin| 2784|358952215806|Optional PvP|2026-01-20 22:59:...|\n",
      "|  10|         Ke vinho|gentebra|    elder druid| 2784|358904530744|Optional PvP|2026-01-20 22:59:...|\n",
      "|  11|    Warlord Bread| belobra|    elder druid| 2782|358463654877|Optional PvP|2026-01-20 22:59:...|\n",
      "|  12|           Baaeck|gentebra|master sorcerer| 2716|333392277789|Optional PvP|2026-01-20 22:59:...|\n",
      "|  13|            Galll|gentebra|   elite knight| 2709|330657551203|Optional PvP|2026-01-20 22:59:...|\n",
      "|  14|   Izzy The Beast| celebra|    elder druid| 2678|319387724396|Optional PvP|2026-01-20 22:59:...|\n",
      "|  15|           Szimix| celesta|    elder druid| 2629|302193405655|Optional PvP|2026-01-20 22:59:...|\n",
      "|  16|             Teus|descubra|master sorcerer| 2621|299594910860|Optional PvP|2026-01-20 22:59:...|\n",
      "|  17|         Ferangel|    bona|  royal paladin| 2583|286876273076|Optional PvP|2026-01-20 22:59:...|\n",
      "|  18|   Khaos Poderoso|  unebra|master sorcerer| 2582|286391478123|    Open PvP|2026-01-20 22:59:...|\n",
      "|  19|Marcao Implacavel| kalibra|    elder druid| 2567|281445783524|Optional PvP|2026-01-20 22:59:...|\n",
      "|  20|       Elder Reno| celesta|    elder druid| 2527|268353964612|Optional PvP|2026-01-20 22:59:...|\n",
      "+----+-----------------+--------+---------------+-----+------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" SELECT * FROM nessie.gold.vocation_rank_global \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1822721f-75e2-42dd-a491-e4a7cf15a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2babc50-2617-4d28-b409-71bb466766c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/26 18:19:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cc27cc-90b9-48ef-8c2f-77a8a63f78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|experience_rank_g...|      false|\n",
      "|     gold|  skills_rank_global|      false|\n",
      "|     gold|vocation_rank_global|      false|\n",
      "|     gold|       world_summary|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1774571-b80e-41f3-8255-0b152cfbd8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    }
   ],
   "source": [
    "tables_gold = [\n",
    "    \"nessie.gold.experience_rank_global\",\n",
    "    \"nessie.gold.skills_rank_global\",\n",
    "    \"nessie.gold.vocation_rank_global\",\n",
    "    \"nessie.gold.world_summary\"\n",
    "]\n",
    "\n",
    "for table in tables_gold:\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04083450-cdfa-49c9-afaa-cb657ada6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|   bronze|   skills|      false|\n",
      "|   bronze| vocation|      false|\n",
      "|   silver|   skills|      false|\n",
      "|   silver| vocation|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04b9eb0-d34c-4bb4-821e-b7f1f3870593",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe69899-b56a-47c7-a1be-c1def3d92017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|              skills|      false|\n",
      "|   bronze|            vocation|      false|\n",
      "|     gold|experience_rank_g...|      false|\n",
      "|     gold|  skills_rank_global|      false|\n",
      "|     gold|       world_summary|      false|\n",
      "|   silver|              skills|      false|\n",
      "|   silver|            vocation|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d512bfa-93b0-4e5d-89f5-d556e3386a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3db209-be30-419f-bfd8-a22dd7ec71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.jobs.utils.utility import create_spark_session\n",
    "spark = create_spark_session(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e369ab39-8f41-4da2-950d-835a88cfa1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 9.6 MB/s eta 0:00:01    |████████████████████████▎       | 9.4 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[K     |████████████████████████████████| 348 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.20.3; python_version < \"3.10\"\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 7.8 MB/s eta 0:00:01    |█████████████▌                  | 7.3 MB 9.1 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 tzdata-2025.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2774b-c982-495d-8e96-882fb5306c1f",
   "metadata": {},
   "source": [
    "# EXPORTANDO AS TABELAS PARA CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c37456b9-3e51-4aa6-9c2e-02740ab837b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/26 19:28:45 WARN S3FileIO: Unclosed S3FileIO instance created by:\n",
      "\torg.apache.iceberg.aws.s3.S3FileIO.initialize(S3FileIO.java:359)\n",
      "\torg.apache.iceberg.CatalogUtil.loadFileIO(CatalogUtil.java:351)\n",
      "\torg.apache.iceberg.nessie.NessieCatalog.initialize(NessieCatalog.java:132)\n",
      "\torg.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:256)\n",
      "\torg.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:310)\n",
      "\torg.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:154)\n",
      "\torg.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:753)\n",
      "\torg.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n",
      "\torg.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:54)\n",
      "\tscala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n",
      "\torg.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:54)\n",
      "\torg.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)\n",
      "\torg.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)\n",
      "\torg.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\n",
      "\torg.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)\n",
      "\torg.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)\n",
      "\torg.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.ShowTables.mapChildren(v2Commands.scala:879)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)\n",
      "\torg.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)\n",
      "\torg.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n",
      "\tscala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tscala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tscala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n",
      "\tscala.collection.immutable.List.foreach(List.scala:431)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)\n",
      "\torg.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n",
      "\torg.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\torg.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)\n",
      "\torg.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\torg.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n",
      "\torg.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n",
      "\torg.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n",
      "\torg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n",
      "\torg.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n",
      "\torg.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\torg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\torg.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
      "\torg.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
      "\torg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\torg.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
      "\torg.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
      "\tjava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tjava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tjava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tjava.base/java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tpy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tpy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tpy4j.Gateway.invoke(Gateway.java:282)\n",
      "\tpy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tpy4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tpy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tpy4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tjava.base/java.lang.Thread.run(Unknown Source)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# BRONZE\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.bronze.vocation\n",
    "    \"\"\").toPandas()).to_csv(\"bronze_vocation.csv\")\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.bronze.skills\n",
    "    \"\"\").toPandas()).to_csv(\"bronze_skills.csv\")\n",
    "\n",
    "# SILVER\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.silver.skills\n",
    "    \"\"\").toPandas()).to_csv(\"silver_skills.csv\")\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.silver.vocation\n",
    "    \"\"\").toPandas()).to_csv(\"silver_vocation.csv\")\n",
    "\n",
    "# GOLD\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.gold.skills_rank_global\n",
    "    \"\"\").toPandas()).to_csv(\"gold_skills_rank_global.csv\")\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.gold.experience_rank_global\n",
    "    \"\"\").toPandas()).to_csv(\"gold_experience_rank_global.csv\")\n",
    "\n",
    "(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM nessie.gold.world_summary\n",
    "    \"\"\").toPandas()).to_csv(\"gold_world_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77ddcc9c-036f-44c5-aa29-df77a9d1503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafacbd-20a1-4eef-b806-96f5629e7555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
